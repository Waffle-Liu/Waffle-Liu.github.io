---
---


@inproceedings{liu2024calibration,
  abbr={ICLR},
  title={On Calibration of LLM-based Guard Models for Reliable Content Moderation},
  author={Liu, Hongfu and Huang, Hengguan and Wang, Hao and Gu, Xiangming and Wang, Ye},
  booktitle={International Conference on Learning Representations (ICLR),},
  notes={Also in NeurIPS Safe GenAI workshop, 2024},
  noteend={(Oral)},
  year={2024},
  pdf={https://arxiv.org/pdf/2410.10414},
  code={https://github.com/Waffle-Liu/calibration_guard_model},
  selected={true},
  abstract={Large language models (LLMs) pose significant risks due to the potential for generating harmful content or users attempting to evade guardrails. Existing studies have developed LLM-based guard models designed to moderate the input and output of threat LLMs, ensuring adherence to safety policies by blocking content that violates these protocols upon deployment. However, limited attention has been given to the reliability and calibration of such guard models. In this work, we empirically conduct comprehensive investigations of confidence calibration for 9 existing LLM-based guard models on 12 benchmarks in both user input and model output classification. Our findings reveal that current LLM-based guard models tend to 1) produce overconfident predictions, 2) exhibit significant miscalibration when subjected to jailbreak attacks, and 3) demonstrate limited robustness to the outputs generated by different types of response models. Additionally, we assess the effectiveness of post-hoc calibration methods to mitigate miscalibration. We demonstrate the efficacy of temperature scaling and, for the first time, highlight the benefits of contextual calibration for confidence calibration of guard models, particularly in the absence of validation sets. Our analysis and experiments underscore the limitations of current LLM-based guard models and provide valuable insights for the future development of well-calibrated guard models toward more reliable content moderation. We also advocate for incorporating reliability evaluation of confidence calibration when releasing future LLM-based guard models.}
}

@inproceedings{liu2024advancing,
  abbr={EMNLP},
  title={Advancing Adversarial Suffix Transfer Learning on Aligned Large Language Models},
  author={Liu*, Hongfu and Xie*, Yuxi and Wang, Ye and Shieh, Michael},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP),},
  notes={Also in NeurIPS Red Teaming GenAI workshop, 2024},
  year={2024},
  pdf={https://arxiv.org/abs/2408.14866},
  code={https://github.com/Waffle-Liu/DeGCG},
  selected={true},
  abstract={Language Language Models (LLMs) face safety concerns due to potential misuse by malicious users. Recent red-teaming efforts have identified adversarial suffixes capable of jailbreaking LLMs using the gradient-based search algorithm Greedy Coordinate Gradient (GCG). However, GCG struggles with computational inefficiency, limiting further investigations regarding suffix transferability and scalability across models and data. In this work, we bridge the connection between search efficiency and suffix transferability. We propose a two-stage transfer learning framework, DeGCG, which decouples the search process into behavior-agnostic pre-searching and behavior-relevant post-searching. Specifically, we employ direct first target token optimization in pre-searching to facilitate the search process. We apply our approach to cross-model, cross-data, and self-transfer scenarios. Furthermore, we introduce an interleaved variant of our approach, i-DeGCG, which iteratively leverages self-transferability to accelerate the search process. Experiments on HarmBench demonstrate the efficiency of our approach across various models and domains. Notably, our i-DeGCG outperforms the baseline on Llama2-chat-7b with ASRs of 43.9 (+22.2) and 39.0 (+19.5) on valid and test sets, respectively. Further analysis on cross-model transfer indicates the pivotal role of first target token optimization in leveraging suffix transferability for efficient searching.}
}

@inproceedings{liu2023advancing,
  abbr={EMNLP},
  title={Advancing Test-Time Adaptation in Wild Acoustic Test Settings},
  author={Liu, Hongfu and Huang, Hengguan and Wang, Ye},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP),},
  year={2024},
  pdf={https://arxiv.org/abs/2310.09505},
  code={https://github.com/Waffle-Liu/CEA},
  selected={true},
  award={Oral},
  abstract={Acoustic foundation models, fine-tuned for Automatic Speech Recognition (ASR), suffer from performance degradation in wild acoustic test settings when deployed in real-world scenarios. Stabilizing online Test-Time Adaptation (TTA) under these conditions remains an open and unexplored question. Existing wild vision TTA methods often fail to handle speech data effectively due to the unique characteristics of high-entropy speech frames, which are unreliably filtered out even when containing crucial semantic content. Furthermore, unlike static vision data, speech signals follow short-term consistency, requiring specialized adaptation strategies. In this work, we propose a novel wild acoustic TTA method tailored for ASR fine-tuned acoustic foundation models. Our method, Confidence-Enhanced Adaptation, performs frame-level adaptation using a confidence-aware weight scheme to avoid filtering out essential information in high-entropy frames. Additionally, we apply consistency regularization during test-time optimization to leverage the inherent short-term consistency of speech signals. Our experiments on both synthetic and real-world datasets demonstrate that our approach outperforms existing baselines under various wild acoustic test settings, including Gaussian noise, environmental sounds, accent variations, and sung speech.}
}

@inproceedings{miao2024discursive,
  abbr={ACL},
  title={Discursive Socratic Questioning: Evaluating the Faithfulness of Language Models{\textquoteright} Understanding of Discourse Relations},
  author={Miao, Yisong and Liu, Hongfu and Lei, Wenqiang and Chen, Nancy F. and Kan, Min-Yen},
  booktitle={Annual Meeting of the Association for Computational Linguistics (ACL),},
  year={2024},
  pdf={https://aclanthology.org/2024.acl-long.341/},
  code={https://github.com/YisongMiao/DiSQ-Score},
  selected={true},
  award={Oral},
  honor={Area Chair Award},
  abstract={While large language models have significantly enhanced the effectiveness of discourse relation classifications, it remains unclear whether their comprehension is faithful and reliable. We provide DiSQ, a new method for evaluating the faithfulness of understanding discourse based on question answering. We first employ in-context learning to annotate the reasoning for discourse comprehension, based on the connections among key events within the discourse. Following this, DiSQ interrogates the model with a sequence of questions to assess its grasp of core event relations, its resilience to counterfactual queries, as well as its consistency to its previous responses. then evaluate language models with different architectural designs using DiSQ, finding: (1) DiSQ presents a significant challenge for all models, with the top-performing GPT model attaining only 41% of the ideal performance in PDTB; (2) DiSQ is robust to domain shifts and paraphrase variations; (3) Open-source models generally lag behind their closed-source GPT counterparts, with notable exceptions being those enhanced with chat and code/math features; (4) Our analysis validates the effectiveness of explicitly signalled discourse connectives, the role of contextual information, and the benefits of using historical QA data.}
}

@inproceedings{huang2024benchmarking,
  abbr={ACL Findings},
  title={Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset},
  author={Huang*, Hengguan and Wang*, Songtao and Liu, Hongfu and Wang, Hao and Wang, Ye},
  booktitle={Findings of Annual Meeting of the Association for Computational Linguistics (ACL),},
  year={2024},
  pdf={https://arxiv.org/abs/2402.05547},
  code={https://github.com/zerowst/Chatcoach},
  selected={true},
  abstract={Traditional applications of natural language processing (NLP) in healthcare have predominantly focused on patient-centered services, enhancing patient interactions and care delivery, such as through medical dialogue systems. However, the potential of NLP to benefit inexperienced doctors, particularly in areas such as communicative medical coaching, remains largely unexplored. We introduce "ChatCoach", a human-AI cooperative framework designed to assist medical learners in practicing their communication skills during patient consultations. ChatCoach differentiates itself from conventional dialogue systems by offering a simulated environment where medical learners can practice dialogues with a patient agent, while a coach agent provides immediate, structured feedback. This is facilitated by our proposed Generalized Chain-of-Thought (GCoT) approach, which fosters the generation of structured feedback and enhances the utilization of external knowledge sources. Additionally, we have developed a dataset specifically for evaluating Large Language Models (LLMs) within the ChatCoach framework on communicative medical coaching tasks. Our empirical results validate the effectiveness of ChatCoach.}
}

@inproceedings{liu2023towards,
  abbr={EMNLP Findings},
  title={Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning},
  author={Liu, Hongfu and Wang, Ye},
  booktitle={Findings of Conference on Empirical Methods in Natural Language Processing (EMNLP),},
  year={2023},
  pdf={https://arxiv.org/abs/2310.08923},
  code={https://waffle-liu.github.io/},
  selected={true},
  abstract={Large Language models (LLMs) possess the capability to engage In-context Learning (ICL) by leveraging a few demonstrations pertaining to a new downstream task as conditions. However, this particular learning paradigm suffers from high instability stemming from substantial variances induced by factors such as the input distribution of selected examples, their ordering, and prompt formats. In this work, we demonstrate that even when all these factors are held constant, the random selection of examples still results in high variance. Consequently, we aim to explore the informative ability of data examples by quantifying the Information Gain (IG) obtained in prediction after observing a given example candidate. Then we propose to sample those with maximum IG. Additionally, we identify the presence of template bias, which can lead to unfair evaluations of IG during the sampling process. To mitigate this bias, we introduce Calibration Before Sampling strategy. The experimental results illustrate that our proposed method can yield an average relative improvement of 14.3% across six classification tasks using three LLMs.}
}

@inproceedings{liu2023zero,
  abbr={Interspeech},
  title={Zero-Shot Automatic Pronunciation Assessment},
  author={Liu, Hongfu and Shi, Mingqian and Wang, Ye},
  booktitle={Interspeech,},
  year={2023},
  pdf={https://arxiv.org/abs/2305.19563},
  selected={true},
  abstract={Automatic Pronunciation Assessment (APA) is vital for computer-assisted language learning. Prior methods rely on annotated speech-text data to train Automatic Speech Recognition (ASR) models or speech-score data to train regression models. In this work, we propose a novel zero-shot APA method based on the pre-trained acoustic model, HuBERT. Our method involves encoding speech input and corrupting them via a masking module. We then employ the Transformer encoder and apply k-means clustering to obtain token sequences. Finally, a scoring module is designed to measure the number of wrongly recovered tokens. Experimental results on speechocean762 demonstrate that the proposed method achieves comparable performance to supervised regression baselines and outperforms non-regression baselines in terms of Pearson Correlation Coefficient (PCC). Additionally, we analyze how masking strategies affect the performance of APA.}
}

@inproceedings{ecbnn,
  abbr={NeurIPS},
  title={Extrapolative Continuous-time Bayesian Neural Network for Fast Training-free Test-time Adaptation},
  author={Huang, Hengguan and Gu, Xiangming and Wang, Hao and Xiao, Chang and Liu, Hongfu and Wang, Ye},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS),},
  year={2022},
  pdf={https://proceedings.neurips.cc/paper_files/paper/2022/file/e9e1a0abc1a5b19a4aeb80dab19c82ae-Paper-Conference.pdf},
  code={https://github.com/guxm2021/ECBNN},
  selected={true},
  abstract={Human intelligence has shown remarkably lower latency and higher precision than most AI systems when processing non-stationary streaming data in real-time. Numerous neuroscience studies suggest that such abilities may be driven by internal predictive modeling. In this paper, we explore the possibility of introducing such a mechanism in unsupervised domain adaptation (UDA) for handling non-stationary streaming data for real-time streaming applications. We propose to formulate internal predictive modeling as a continuous-time Bayesian filtering problem within a stochastic dynamical system context. Such a dynamical system describes the dynamics of model parameters of a UDA model evolving with non-stationary streaming data. Building on such a dynamical system, we then develop extrapolative continuous-time Bayesian neural networks (ECBNN), which generalize existing Bayesian neural networks to represent temporal dynamics and allow us to extrapolate the distribution of model parameters before observing the incoming data, therefore effectively reducing the latency. Remarkably, our empirical results show that ECBNN is capable of continuously generating better distributions of model parameters along the time axis given historical data only, thereby achieving (1) training-free test-time adaptation with low latency, (2) gradually improved alignment between the source and target features and (3) gradually improved model performance over time during the real-time testing stage.}
}

@inproceedings{huang2021strode,
  abbr={ICML},
  title={STRODE: Stochastic Boundary Ordinary Differential Equation},
  author={Huang, Hengguan and Liu, Hongfu and Wang, Hao and Xiao, Chang and Wang, Ye},
  booktitle={International Conference on Machine Learning (ICML),},
  pages={4435--4445},
  year={2021},
  organization={PMLR},
  pdf={https://arxiv.org/abs/2107.08273},
  code={https://github.com/Waffle-Liu/STRODE},
  selected={true},
  abstract={Perception of time from sequentially acquired sensory inputs is rooted in everyday behaviors of individual organisms. Yet, most algorithms for time-series modeling fail to learn dynamics of random event timings directly from visual or audio inputs, requiring timing annotations during training that are usually unavailable for real-world applications. For instance, neuroscience perspectives on postdiction imply that there exist variable temporal ranges within which the incoming sensory inputs can affect the earlier perception, but such temporal ranges are mostly unannotated for real applications such as automatic speech recognition (ASR). In this paper, we present a probabilistic ordinary differential equation (ODE), called STochastic boundaRy ODE (STRODE), that learns both the timings and the dynamics of time series data without requiring any timing annotations during training. STRODE allows the usage of differential equations to sample from the posterior point processes, efficiently and analytically. We further provide theoretical guarantees on the learning of STRODE. Our empirical results show that our approach successfully infers event timings of time series data. Our method achieves competitive or superior performances compared to existing state-of-the-art methods for both synthetic and real-world datasets.}
}

@inproceedings{cella2020study,
  abbr={CSMC+ MuMe},
  title={A Study on Neural Models for Target-Based Computer-Assisted Musical Orchestration},
  author={Cella, Carmine and Dzwonczyk, Luke and Saldarriaga-Fuertes, Alejandro and Liu, Hongfu and Crayencour, Helene-Camille},
  booktitle={2020 Joint Conference on AI Music Creativity (CSMC+ MuMe)},
  year={2020},
  pdf={https://hal.archives-ouvertes.fr/hal-03059955/document},
  selected={false}
}

@inproceedings{qiu2019mind,
  abbr={ACM MM},
  title={Mind Band: a crossmedia AI music composing platform},
  author={Qiu, Zhaolin and Ren, Yufan and Li, Canchen and Liu, Hongfu and Huang, Yifan and Yang, Yiheng and Wu, Songruoyao and Zheng, Hanjia and Ji, Juntao and Yu, Jianjia and others},
  booktitle={Proceedings of the 27th ACM international conference on multimedia},
  pages={2231--2233},
  year={2019},
  pdf={https://www.researchgate.net/profile/Canchen-Li/publication/336706528_Mind_Band_A_Crossmedia_AI_Music_Composing_Platform/links/5dcb2215a6fdcc575043f3eb/Mind-Band-A-Crossmedia-AI-Music-Composing-Platform.pdf},
  selected={false}
}

